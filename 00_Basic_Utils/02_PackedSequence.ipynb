{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch PackedSequence Tutorial\n",
    "---\n",
    "\n",
    "This article is optimized at [nbviewer](https://nbviewer.jupyter.org/github/simonjisu/pytorch_tutorials/blob/master/00_Basic/PackedSequence/PackedSequence_Tutorial.ipynb) or clone this [repo](https://github.com/simonjisu/pytorch_tutorials.git)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Preprocessing](#1.-Preprocessing)\n",
    "2. [How to use PackedSequence object in pytorch](#2.-How-to-use-PackedSequence-object-in-pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig1](./figs/0705img1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "figure from: https://medium.com/huggingface/understanding-emotions-from-keras-to-pytorch-3ccb61d5a983 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing\n",
    "\n",
    "Always have to do this preprocessing, while you are working on NLP.\n",
    "\n",
    "* make vocabulary, one token matches single unique index.\n",
    "* add <pad> token.\n",
    "* change all tokens to vocabulary index that you made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "batch_data = [\"I love Mom ' s cooking\", \"I love you too !\", \"No way\", \"This is the shit\", \"Yes\"]\n",
    "input_seq = [s.split() for s in batch_data]\n",
    "max_len = 0\n",
    "for s in input_seq:\n",
    "    if len(s) >= max_len:\n",
    "        max_len = len(s)\n",
    "vocab = {w: i for i, w in enumerate(set([t for s in input_seq for t in s]), 1)}\n",
    "vocab[\"<pad>\"] = 0\n",
    "input_seq = [s+[\"<pad>\"]*(max_len-len(s)) if len(s) < max_len else s for s in input_seq]\n",
    "input_seq2idx = torch.LongTensor([list(map(vocab.get, s)) for s in input_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I', 'love', 'Mom', \"'\", 's', 'cooking'],\n",
       " ['I', 'love', 'you', 'too', '!', '<pad>'],\n",
       " ['No', 'way', '<pad>', '<pad>', '<pad>', '<pad>'],\n",
       " ['This', 'is', 'the', 'shit', '<pad>', '<pad>'],\n",
       " ['Yes', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14,  8,  7, 16,  1, 15],\n",
       "        [14,  8,  4,  2, 10,  0],\n",
       "        [ 5, 11,  0,  0,  0,  0],\n",
       "        [ 3,  9, 12, 13,  0,  0],\n",
       "        [ 6,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How to use PackedSequence object in pytorch\n",
    "\n",
    "1. [using pack_padded_sequence](#2.1-using-pack_padded_sequence)\n",
    "2. [usage in RNN](#2.2-usage-in-RNN)\n",
    "3. [unpack to get output](#2.3-unpack-to-get-output)\n",
    "4. [last hidden state mapped to output](#2.4-last-hidden-state-mapped-to-output)\n",
    "\n",
    "### 2.1 using pack_padded_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change batch matrix in a decreasing order of sentence length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig2](./figs/0705img2.png)\n",
    "\n",
    "figure from: https://medium.com/huggingface/understanding-emotions-from-keras-to-pytorch-3ccb61d5a983 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lengths = torch.LongTensor([torch.max(input_seq2idx[i, :].data.nonzero())+1 \n",
    "                                  for i in range(input_seq2idx.size(0))])\n",
    "input_lengths, sorted_idx = input_lengths.sort(0, descending=True)\n",
    "input_seq2idx = input_seq2idx[sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14,  8,  7, 16,  1, 15],\n",
       "        [14,  8,  4,  2, 10,  0],\n",
       "        [ 3,  9, 12, 13,  0,  0],\n",
       "        [ 5, 11,  0,  0,  0,  0],\n",
       "        [ 6,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 5, 4, 2, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lengths  # length of each sentences in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_input = pack_padded_sequence(input_seq2idx, input_lengths.tolist(), batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "tensor([14, 14,  3,  5,  6,  8,  8,  9, 11,  7,  4, 12, 16,  2, 13,  1, 10, 15])\n",
      "tensor([5, 4, 3, 3, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "print(type(packed_input))\n",
    "print(packed_input[0])  # packed data\n",
    "print(packed_input[1])  # batch_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 usage in RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any RNN type(RNN, LSTM, GRU) that you use it's not matter.\n",
    "\n",
    "Also, normaliy we use `Embedding layer` to map all tokens to a real number vector space. In traning step, let the network learn the suitable sapce to solve a task. If you don't familiar with `Embedding layer` search under references.\n",
    "\n",
    "* Pytorch documentation: https://pytorch.org/docs/stable/nn.html?highlight=embedding#torch.nn.Embedding\n",
    "* presented some picture how embedding works in my blog (korean) https://simonjisu.github.io/nlp/2018/04/20/allaboutwv2.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "hidden_size = 1\n",
    "embedding_size = 5\n",
    "num_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n",
    "gru = nn.RNN(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers, \n",
    "             bidirectional=False, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded = embed(input_seq2idx)\n",
    "packed_input = pack_padded_sequence(embeded, input_lengths.tolist(), batch_first=True)\n",
    "packed_output, hidden = gru(packed_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([18, 1]), tensor([5, 4, 3, 3, 2, 1], grad_fn=<PackPaddedBackward>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_output[0].size(), packed_output[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 unpack to get output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, output_lengths = pad_packed_sequence(packed_output, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 6, 1]), tensor([6, 5, 4, 2, 1]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size(), output_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it fills all <pad\\> output as zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5452],\n",
       "        [0.5452],\n",
       "        [0.5571],\n",
       "        [0.5942],\n",
       "        [0.5959],\n",
       "        [0.4812],\n",
       "        [0.4812],\n",
       "        [0.4254],\n",
       "        [0.4137],\n",
       "        [0.5322],\n",
       "        [0.5655],\n",
       "        [0.5119],\n",
       "        [0.4390],\n",
       "        [0.4866],\n",
       "        [0.5362],\n",
       "        [0.4834],\n",
       "        [0.5585],\n",
       "        [0.5477]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5452],\n",
       "         [0.4812],\n",
       "         [0.5322],\n",
       "         [0.4390],\n",
       "         [0.4834],\n",
       "         [0.5477]],\n",
       "\n",
       "        [[0.5452],\n",
       "         [0.4812],\n",
       "         [0.5655],\n",
       "         [0.4866],\n",
       "         [0.5585],\n",
       "         [0.0000]],\n",
       "\n",
       "        [[0.5571],\n",
       "         [0.4254],\n",
       "         [0.5119],\n",
       "         [0.5362],\n",
       "         [0.0000],\n",
       "         [0.0000]],\n",
       "\n",
       "        [[0.5942],\n",
       "         [0.4137],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000]],\n",
       "\n",
       "        [[0.5959],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 last hidden state mapped to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_white(val):\n",
    "    color = 'white' if val == 0 else 'black'\n",
    "    return 'color: {}'.format(color)\n",
    "def color_red(data):\n",
    "    max_len = len(data)\n",
    "    fmt = 'color: red'\n",
    "    lst = []\n",
    "    for i, v in enumerate(data):\n",
    "        if (v != 0) and (i == max_len-1):\n",
    "            lst.append(fmt)\n",
    "        elif (v != 0) and (data[i+1] == 0):\n",
    "            lst.append(fmt)\n",
    "        else:\n",
    "            lst.append('')\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow0_col0 {\n",
       "            color:  black;\n",
       "            : ;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow0_col1 {\n",
       "            color:  black;\n",
       "            : ;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow0_col2 {\n",
       "            color:  black;\n",
       "            : ;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow0_col3 {\n",
       "            color:  black;\n",
       "            : ;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow0_col4 {\n",
       "            color:  black;\n",
       "            : ;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow0_col5 {\n",
       "            color:  black;\n",
       "            color:  red;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow1_col0 {\n",
       "            color:  black;\n",
       "            : ;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow1_col1 {\n",
       "            color:  black;\n",
       "            : ;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow1_col2 {\n",
       "            color:  black;\n",
       "            : ;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow1_col3 {\n",
       "            color:  black;\n",
       "            : ;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow1_col4 {\n",
       "            color:  black;\n",
       "            color:  red;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow1_col5 {\n",
       "            color:  white;\n",
       "            : ;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow2_col0 {\n",
       "            color:  black;\n",
       "            : ;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow2_col1 {\n",
       "            color:  black;\n",
       "            : ;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow2_col2 {\n",
       "            color:  black;\n",
       "            : ;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow2_col3 {\n",
       "            color:  black;\n",
       "            color:  red;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow2_col4 {\n",
       "            color:  white;\n",
       "            : ;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow2_col5 {\n",
       "            color:  white;\n",
       "            : ;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow3_col0 {\n",
       "            color:  black;\n",
       "            : ;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow3_col1 {\n",
       "            color:  black;\n",
       "            color:  red;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow3_col2 {\n",
       "            color:  white;\n",
       "            : ;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow3_col3 {\n",
       "            color:  white;\n",
       "            : ;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow3_col4 {\n",
       "            color:  white;\n",
       "            : ;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow3_col5 {\n",
       "            color:  white;\n",
       "            : ;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow4_col0 {\n",
       "            color:  black;\n",
       "            color:  red;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow4_col1 {\n",
       "            color:  white;\n",
       "            : ;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow4_col2 {\n",
       "            color:  white;\n",
       "            : ;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow4_col3 {\n",
       "            color:  white;\n",
       "            : ;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow4_col4 {\n",
       "            color:  white;\n",
       "            : ;\n",
       "        }    #T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow4_col5 {\n",
       "            color:  white;\n",
       "            : ;\n",
       "        }</style>  \n",
       "<table id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdc\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"index_name level0\" >hidden_step</th> \n",
       "        <th class=\"col_heading level0 col0\" >0</th> \n",
       "        <th class=\"col_heading level0 col1\" >1</th> \n",
       "        <th class=\"col_heading level0 col2\" >2</th> \n",
       "        <th class=\"col_heading level0 col3\" >3</th> \n",
       "        <th class=\"col_heading level0 col4\" >4</th> \n",
       "        <th class=\"col_heading level0 col5\" >5</th> \n",
       "    </tr>    <tr> \n",
       "        <th class=\"index_name level0\" >batch</th> \n",
       "        <th class=\"blank\" ></th> \n",
       "        <th class=\"blank\" ></th> \n",
       "        <th class=\"blank\" ></th> \n",
       "        <th class=\"blank\" ></th> \n",
       "        <th class=\"blank\" ></th> \n",
       "        <th class=\"blank\" ></th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdclevel0_row0\" class=\"row_heading level0 row0\" >0</th> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow0_col0\" class=\"data row0 col0\" >0.5452</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow0_col1\" class=\"data row0 col1\" >0.4812</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow0_col2\" class=\"data row0 col2\" >0.5322</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow0_col3\" class=\"data row0 col3\" >0.439</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow0_col4\" class=\"data row0 col4\" >0.4834</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow0_col5\" class=\"data row0 col5\" >0.5477</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdclevel0_row1\" class=\"row_heading level0 row1\" >1</th> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow1_col0\" class=\"data row1 col0\" >0.5452</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow1_col1\" class=\"data row1 col1\" >0.4812</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow1_col2\" class=\"data row1 col2\" >0.5655</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow1_col3\" class=\"data row1 col3\" >0.4866</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow1_col4\" class=\"data row1 col4\" >0.5585</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow1_col5\" class=\"data row1 col5\" >0</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdclevel0_row2\" class=\"row_heading level0 row2\" >2</th> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow2_col0\" class=\"data row2 col0\" >0.5571</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow2_col1\" class=\"data row2 col1\" >0.4254</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow2_col2\" class=\"data row2 col2\" >0.5119</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow2_col3\" class=\"data row2 col3\" >0.5362</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow2_col4\" class=\"data row2 col4\" >0</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow2_col5\" class=\"data row2 col5\" >0</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdclevel0_row3\" class=\"row_heading level0 row3\" >3</th> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow3_col0\" class=\"data row3 col0\" >0.5942</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow3_col1\" class=\"data row3 col1\" >0.4137</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow3_col2\" class=\"data row3 col2\" >0</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow3_col3\" class=\"data row3 col3\" >0</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow3_col4\" class=\"data row3 col4\" >0</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow3_col5\" class=\"data row3 col5\" >0</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdclevel0_row4\" class=\"row_heading level0 row4\" >4</th> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow4_col0\" class=\"data row4 col0\" >0.5959</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow4_col1\" class=\"data row4 col1\" >0</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow4_col2\" class=\"data row4 col2\" >0</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow4_col3\" class=\"data row4 col3\" >0</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow4_col4\" class=\"data row4 col4\" >0</td> \n",
       "        <td id=\"T_850c339e_d1ea_11e8_a5b7_e0d55e4d0bdcrow4_col5\" class=\"data row4 col5\" >0</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff5a3430b70>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.concatenate([o.detach().numpy() for o in output.transpose(0, 1)], axis=1).round(4))\n",
    "df.index.name = 'batch'\n",
    "df.columns.name = 'hidden_step'\n",
    "df.style.applymap(color_white).apply(color_red, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **red vectors** are last hidden vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5477],\n",
       "        [0.5585],\n",
       "        [0.5362],\n",
       "        [0.4137],\n",
       "        [0.5959]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5452],\n",
       "         [0.5452],\n",
       "         [0.5571],\n",
       "         [0.5942],\n",
       "         [0.5959],\n",
       "         [0.4812],\n",
       "         [0.4812],\n",
       "         [0.4254],\n",
       "         [0.4137],\n",
       "         [0.5322],\n",
       "         [0.5655],\n",
       "         [0.5119],\n",
       "         [0.4390],\n",
       "         [0.4866],\n",
       "         [0.5362],\n",
       "         [0.4834],\n",
       "         [0.5585],\n",
       "         [0.5477]], grad_fn=<CatBackward>),\n",
       " tensor([5, 4, 3, 3, 2, 1], grad_fn=<PackPaddedBackward>))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_output[0], packed_output[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
