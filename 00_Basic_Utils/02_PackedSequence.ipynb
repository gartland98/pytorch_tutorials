{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch PackedSequence Tutorial\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Preprocessing](#1.-Preprocessing)\n",
    "2. [How to use PackedSequence object in pytorch](#2.-How-to-use-PackedSequence-object-in-pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig1](./figs/0705img1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "figure from: https://medium.com/huggingface/understanding-emotions-from-keras-to-pytorch-3ccb61d5a983 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing\n",
    "\n",
    "Always have to do this preprocessing, while you are working on NLP.\n",
    "\n",
    "* make vocabulary, one token matches single unique index.\n",
    "* add <pad> token.\n",
    "* change all tokens to vocabulary index that you made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "batch_data = [\"I love Mom ' s cooking\", \"I love you too !\", \"No way\", \"This is the shit\", \"Yes\"]\n",
    "input_seq = [s.split() for s in batch_data]\n",
    "max_len = 0\n",
    "for s in input_seq:\n",
    "    if len(s) >= max_len:\n",
    "        max_len = len(s)\n",
    "vocab = {w: i for i, w in enumerate(set([t for s in input_seq for t in s]), 1)}\n",
    "vocab[\"<pad>\"] = 0\n",
    "input_seq = [s+[\"<pad>\"]*(max_len-len(s)) if len(s) < max_len else s for s in input_seq]\n",
    "input_seq2idx = torch.LongTensor([list(map(vocab.get, s)) for s in input_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I', 'love', 'Mom', \"'\", 's', 'cooking'],\n",
       " ['I', 'love', 'you', 'too', '!', '<pad>'],\n",
       " ['No', 'way', '<pad>', '<pad>', '<pad>', '<pad>'],\n",
       " ['This', 'is', 'the', 'shit', '<pad>', '<pad>'],\n",
       " ['Yes', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 13,   9,   3,  15,   1,   2],\n",
       "        [ 13,   9,  10,   4,  16,   0],\n",
       "        [  7,  11,   0,   0,   0,   0],\n",
       "        [  6,  12,   8,  14,   0,   0],\n",
       "        [  5,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How to use PackedSequence object in pytorch\n",
    "\n",
    "1. [using pack_padded_sequence](#2.1-using-pack_padded_sequence)\n",
    "2. [usage in RNN](#2.2-usage-in-RNN)\n",
    "3. [unpack to get output](#2.3-unpack-to-get-output)\n",
    "4. [last hidden state mapped to output](#2.4-last-hidden-state-mapped-to-output)\n",
    "\n",
    "### 2.1 using pack_padded_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change batch matrix in a decreasing order of sentence length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig2](./figs/0705img2.png)\n",
    "\n",
    "figure from: https://medium.com/huggingface/understanding-emotions-from-keras-to-pytorch-3ccb61d5a983 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lengths = torch.LongTensor([torch.max(input_seq2idx[i, :].data.nonzero())+1 \n",
    "                                  for i in range(input_seq2idx.size(0))])\n",
    "input_lengths, sorted_idx = input_lengths.sort(0, descending=True)\n",
    "input_seq2idx = input_seq2idx[sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 13,   9,   3,  15,   1,   2],\n",
       "        [ 13,   9,  10,   4,  16,   0],\n",
       "        [  6,  12,   8,  14,   0,   0],\n",
       "        [  7,  11,   0,   0,   0,   0],\n",
       "        [  5,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  5,  4,  2,  1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lengths  # length of each sentences in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_input = pack_padded_sequence(input_seq2idx, input_lengths.tolist(), batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "tensor([ 13,  13,   6,   7,   5,   9,   9,  12,  11,   3,  10,   8,\n",
      "         15,   4,  14,   1,  16,   2])\n",
      "tensor([ 5,  4,  3,  3,  2,  1])\n"
     ]
    }
   ],
   "source": [
    "print(type(packed_input))\n",
    "print(packed_input[0])  # packed data\n",
    "print(packed_input[1])  # batch_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 usage in RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any RNN type(RNN, LSTM, GRU) that you use it's not matter.\n",
    "\n",
    "Also, normaliy we use `Embedding layer` to map all tokens to a real number vector space. In traning step, let the network learn the suitable sapce to solve a task. If you don't familiar with `Embedding layer` search under references.\n",
    "\n",
    "* Pytorch documentation: https://pytorch.org/docs/stable/nn.html?highlight=embedding#torch.nn.Embedding\n",
    "* presented some picture how embedding works in my blog (korean) https://simonjisu.github.io/nlp/2018/04/20/allaboutwv2.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "hidden_size = 2\n",
    "embedding_size = 5\n",
    "num_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n",
    "gru = nn.RNN(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers, \n",
    "             bidirectional=False, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded = embed(input_seq2idx)\n",
    "packed_input = pack_padded_sequence(embeded, input_lengths.tolist(), batch_first=True)\n",
    "packed_output, hidden = gru(packed_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([18, 2]), tensor([ 5,  4,  3,  3,  2,  1]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_output[0].size(), packed_output[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 unpack to get output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, output_lengths = pad_packed_sequence(packed_output, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 6, 2]), tensor([ 6,  5,  4,  2,  1]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size(), output_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it fills all <pad\\> output as zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1857, -0.0526],\n",
       "        [ 0.1857, -0.0526],\n",
       "        [ 0.0081,  0.1482],\n",
       "        [-0.2469,  0.2890],\n",
       "        [ 0.0385,  0.0846],\n",
       "        [ 0.2779,  0.0454],\n",
       "        [ 0.2779,  0.0454],\n",
       "        [-0.3101,  0.2290],\n",
       "        [ 0.0850, -0.4064],\n",
       "        [ 0.4876, -0.2039],\n",
       "        [ 0.1064,  0.2356],\n",
       "        [ 0.2403, -0.5423],\n",
       "        [ 0.3256,  0.3797],\n",
       "        [ 0.3147, -0.2829],\n",
       "        [ 0.3291,  0.3525],\n",
       "        [-0.1685,  0.2127],\n",
       "        [ 0.2733,  0.3111],\n",
       "        [ 0.0675, -0.3163]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1857, -0.0526],\n",
       "         [ 0.2779,  0.0454],\n",
       "         [ 0.4876, -0.2039],\n",
       "         [ 0.3256,  0.3797],\n",
       "         [-0.1685,  0.2127],\n",
       "         [ 0.0675, -0.3163]],\n",
       "\n",
       "        [[ 0.1857, -0.0526],\n",
       "         [ 0.2779,  0.0454],\n",
       "         [ 0.1064,  0.2356],\n",
       "         [ 0.3147, -0.2829],\n",
       "         [ 0.2733,  0.3111],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0081,  0.1482],\n",
       "         [-0.3101,  0.2290],\n",
       "         [ 0.2403, -0.5423],\n",
       "         [ 0.3291,  0.3525],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.2469,  0.2890],\n",
       "         [ 0.0850, -0.4064],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0385,  0.0846],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 last hidden state mapped to output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|0|1|2|3|4|5|\n",
    "|-|-|-|-|-|-|-|\n",
    "|[ 0.1857, -0.0526]|[ 0.2779,  0.0454]|[ 0.4876, -0.2039]|[ 0.3256,  0.3797]|[-0.1685,  0.2127]|**[ 0.0675, -0.3163]**|\n",
    "|[ 0.1857, -0.0526]|[ 0.2779,  0.0454]|[ 0.1064,  0.2356]|[ 0.3147, -0.2829]|**[ 0.2733,  0.3111]**||\n",
    "|[ 0.0081,  0.1482]|[-0.3101,  0.2290]|[ 0.2403, -0.5423]|**[ 0.3291,  0.3525]**|||||\n",
    "|[-0.2469,  0.2890]|**[ 0.0850, -0.4064]**|||||\n",
    "|**[ 0.0385,  0.0846]**||||||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **bolded vectors** are last hidden vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0675, -0.3163],\n",
       "        [ 0.2733,  0.3111],\n",
       "        [ 0.3291,  0.3525],\n",
       "        [ 0.0850, -0.4064],\n",
       "        [ 0.0385,  0.0846]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1857, -0.0526],\n",
       "         [ 0.1857, -0.0526],\n",
       "         [ 0.0081,  0.1482],\n",
       "         [-0.2469,  0.2890],\n",
       "         [ 0.0385,  0.0846],\n",
       "         [ 0.2779,  0.0454],\n",
       "         [ 0.2779,  0.0454],\n",
       "         [-0.3101,  0.2290],\n",
       "         [ 0.0850, -0.4064],\n",
       "         [ 0.4876, -0.2039],\n",
       "         [ 0.1064,  0.2356],\n",
       "         [ 0.2403, -0.5423],\n",
       "         [ 0.3256,  0.3797],\n",
       "         [ 0.3147, -0.2829],\n",
       "         [ 0.3291,  0.3525],\n",
       "         [-0.1685,  0.2127],\n",
       "         [ 0.2733,  0.3111],\n",
       "         [ 0.0675, -0.3163]]), tensor([ 5,  4,  3,  3,  2,  1]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_output[0], packed_output[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
